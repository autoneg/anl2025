{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "formed-honey",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:95% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# setup disply parameters\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "float_formatter = StrMethodFormatter('{x:0.03f}')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('figure', figsize=(18, 6)) # set figure size\n",
    "plt.rc(\"animation\", html=\"html5\")\n",
    "import random\n",
    "random.seed(203)\n",
    "import numpy as np\n",
    "np.random.seed(345)\n",
    "import matplotlib.pyplot as plt\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "moving-telephone",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88578a3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ANL 2025 Tutorial\n",
    "\n",
    "## Developing a Negotiator\n",
    "\n",
    "The agents for the ANL competition are simple extensions of [NegMAS](https://yasserfarouk.github.io/negmas) negotiators. As such, they can be developed using any approach used to develop negotiators in NegMAS.\n",
    "\n",
    "To develop a negotiator, you need to inherit from the [ANL2025Negotiator](http://www.yasserm.com/anl2025tmp/reference/#anl2025.negotiator.ANL2025Negotiator) class and implement the [`propose()`](http://www.yasserm.com/anl2025tmp/reference/#anl2025.negotiator.ANL2025Negotiator.propose) and [`respond()`](http://www.yasserm.com/anl2025tmp/reference/#anl2025.negotiator.ANL2025Negotiator.respond).\n",
    "\n",
    "Here is a simple random negotiator: (test 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddbac4ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from negmas import Outcome, ResponseType, SAOState\n",
    "from anl2025 import ANL2025Negotiator\n",
    "\n",
    "\n",
    "class MyRandom2025(ANL2025Negotiator):\n",
    "    p_end = 0.03\n",
    "    p_reject = 0.999\n",
    "\n",
    "    def propose(\n",
    "        self, negotiator_id: str, state: SAOState, dest: str | None = None\n",
    "    ) -> Outcome | None:\n",
    "        nmi = self.negotiators[negotiator_id].negotiator.nmi        \n",
    "        return list(nmi.outcome_space.sample(1))[0]\n",
    "\n",
    "    def respond(\n",
    "        self, negotiator_id: str, state: SAOState, source: str | None = None\n",
    "    ) -> ResponseType:        \n",
    "        if random() < self.p_end:\n",
    "            return ResponseType.END_NEGOTIATION\n",
    "\n",
    "        if (\n",
    "            random() < self.p_reject\n",
    "            or float(self.ufun(state.current_offer)) < self.ufun.reserved_value  # type: ignore\n",
    "        ):\n",
    "            return ResponseType.REJECT_OFFER\n",
    "        return ResponseType.ACCEPT_OFFER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-bulgaria",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Testing the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "detected-toilet",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from anl.anl2024 import anl2024_tournament\n",
    "from anl.anl2024.negotiators import Boulware, Conceder, RVFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dynamic-breath",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Will run \u001B[1;36m12\u001B[0m negotiations on \u001B[1;36m1\u001B[0m scenarios between \u001B[1;36m2\u001B[0m competitors\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Will run <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> negotiations on <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> scenarios between <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> competitors\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b176fa99e5f54df5bcc75f219b1cfd35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Rational.__init__() got an unexpected keyword argument 'private_info'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43manl2024_tournament\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_scenarios\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_repetitions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnologs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnjobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompetitors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mMyRandom2025\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBoulware\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\5856442\\onedrive - universiteit utrecht\\documents\\github\\anl2025tmp\\venv\\src\\anl\\src\\anl\\anl2024\\runner.py:835\u001B[0m, in \u001B[0;36manl2024_tournament\u001B[1;34m(scenarios, n_scenarios, n_outcomes, competitors, rotate_ufuns, n_repetitions, n_steps, time_limit, hidden_time_limit, pend, pend_per_second, step_time_limit, negotiator_time_limit, self_play, randomize_runs, sort_runs, known_partner, final_score, scenario_generator, generator_params, competitor_params, name, nologs, njobs, plot_fraction, verbosity, save_every, save_stats, base_path, plot_params, raise_exceptions)\u001B[0m\n\u001B[0;32m    817\u001B[0m scenarios \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(scenarios) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m    818\u001B[0m     scenario_generator(n_scenarios, n_outcomes, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgenerator_params)\n\u001B[0;32m    819\u001B[0m )\n\u001B[0;32m    820\u001B[0m private_infos \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;28mtuple\u001B[39m(\n\u001B[0;32m    822\u001B[0m         \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    833\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m scenarios\n\u001B[0;32m    834\u001B[0m ]\n\u001B[1;32m--> 835\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcartesian_tournament\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompetitors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcompetitors\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    837\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscenarios\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscenarios\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    838\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompetitor_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompetitor_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprivate_infos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprivate_infos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[0;32m    840\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrotate_ufuns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrotate_ufuns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_repetitions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_repetitions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnjobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnjobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmechanism_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSAOMechanism\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_time_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_time_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpend_per_second\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpend_per_second\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstep_time_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep_time_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnegotiator_time_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnegotiator_time_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmechanism_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplot_fraction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplot_fraction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbosity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[43m    \u001B[49m\u001B[43mself_play\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_play\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandomize_runs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandomize_runs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort_runs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort_runs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    858\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_every\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    859\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_stats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_stats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    860\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfinal_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfinal_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    861\u001B[0m \u001B[43m    \u001B[49m\u001B[43mid_reveals_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mknown_partner\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    862\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname_reveals_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    863\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplot_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraise_exceptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraise_exceptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\anl2025tmp\\venv\\src\\negmas\\src\\negmas\\tournaments\\neg\\simple\\cartesian.py:1448\u001B[0m, in \u001B[0;36mcartesian_tournament\u001B[1;34m(competitors, scenarios, private_infos, competitor_params, rotate_ufuns, rotate_private_infos, n_repetitions, path, njobs, mechanism_type, mechanism_params, n_steps, time_limit, pend, pend_per_second, step_time_limit, negotiator_time_limit, hidden_time_limit, external_timeout, plot_fraction, plot_params, verbosity, self_play, randomize_runs, sort_runs, save_every, save_stats, save_scenario_figs, final_score, id_reveals_type, name_reveals_type, shorten_names, raise_exceptions, mask_scenario_names, only_failures_on_self_play, python_class_identifier)\u001B[0m\n\u001B[0;32m   1444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m njobs \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1445\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, info \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\n\u001B[0;32m   1446\u001B[0m         track(runs, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(runs), description\u001B[38;5;241m=\u001B[39mNEGOTIATIONS_DIR_NAME)\n\u001B[0;32m   1447\u001B[0m     ):\n\u001B[1;32m-> 1448\u001B[0m         process_record(\u001B[43mrun_negotiation\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_run_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43minfo\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1450\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1451\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m external_timeout \u001B[38;5;28;01mif\u001B[39;00m external_timeout \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\anl2025tmp\\venv\\src\\negmas\\src\\negmas\\tournaments\\neg\\simple\\cartesian.py:936\u001B[0m, in \u001B[0;36mrun_negotiation\u001B[1;34m(s, partners, partner_names, partner_params, rep, path, mechanism_type, mechanism_params, full_names, verbosity, plot, plot_params, run_id, stats, annotation, private_infos, id_reveals_type, name_reveals_type, mask_scenario_name, ignore_exceptions)\u001B[0m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrun_negotiation\u001B[39m(\n\u001B[0;32m    887\u001B[0m     s: Scenario,\n\u001B[0;32m    888\u001B[0m     partners: \u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28mtype\u001B[39m[Negotiator]],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    906\u001B[0m     ignore_exceptions: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    907\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m    908\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    909\u001B[0m \u001B[38;5;124;03m    Run a single negotiation with fully specified parameters\u001B[39;00m\n\u001B[0;32m    910\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;124;03m        A dictionary of negotiation results that contains the final state of the negotiation alongside other information\u001B[39;00m\n\u001B[0;32m    935\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 936\u001B[0m     m, failures, s, real_scenario_name \u001B[38;5;241m=\u001B[39m \u001B[43m_make_mechanism\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    937\u001B[0m \u001B[43m        \u001B[49m\u001B[43ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    938\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartners\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartners\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    939\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartner_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartner_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    940\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartner_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartner_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    941\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    942\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmechanism_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmechanism_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmechanism_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmechanism_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfull_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfull_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mannotation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mannotation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    948\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprivate_infos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprivate_infos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    949\u001B[0m \u001B[43m        \u001B[49m\u001B[43mid_reveals_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mid_reveals_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    950\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname_reveals_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname_reveals_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmask_scenario_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask_scenario_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    952\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_exceptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_exceptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    953\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    954\u001B[0m     reservations \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(u\u001B[38;5;241m.\u001B[39mreserved_value \u001B[38;5;28;01mfor\u001B[39;00m u \u001B[38;5;129;01min\u001B[39;00m s\u001B[38;5;241m.\u001B[39mufuns)\n\u001B[0;32m    955\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m partner_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\anl2025tmp\\venv\\src\\negmas\\src\\negmas\\tournaments\\neg\\simple\\cartesian.py:615\u001B[0m, in \u001B[0;36m_make_mechanism\u001B[1;34m(s, partners, partner_names, partner_params, rep, path, mechanism_type, mechanism_params, full_names, verbosity, run_id, annotation, private_infos, id_reveals_type, name_reveals_type, mask_scenario_name, ignore_exceptions)\u001B[0m\n\u001B[0;32m    613\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    614\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 615\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m (e)\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m failures:\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m m, failures, s, real_scenario_name\n",
      "File \u001B[1;32m~\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\anl2025tmp\\venv\\src\\negmas\\src\\negmas\\tournaments\\neg\\simple\\cartesian.py:600\u001B[0m, in \u001B[0;36m_make_mechanism\u001B[1;34m(s, partners, partner_names, partner_params, rep, path, mechanism_type, mechanism_params, full_names, verbosity, run_id, annotation, private_infos, id_reveals_type, name_reveals_type, mask_scenario_name, ignore_exceptions)\u001B[0m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m type_, p, pinfo \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(partners, partner_params, private_infos):  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m    599\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 600\u001B[0m         negotiator \u001B[38;5;241m=\u001B[39m \u001B[43mtype_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprivate_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpinfo\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    601\u001B[0m         name \u001B[38;5;241m=\u001B[39m _name(negotiator)\n\u001B[0;32m    602\u001B[0m         complete_names\u001B[38;5;241m.\u001B[39mappend(name)\n",
      "File \u001B[1;32m~\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\anl2025tmp\\venv\\src\\anl2025\\src\\anl2025\\negotiator.py:33\u001B[0m, in \u001B[0;36mANL2025Negotiator.__init__\u001B[1;34m(self, n_edges, *args, **kwargs)\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, n_edges: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 33\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_edges \u001B[38;5;241m=\u001B[39m n_edges\n",
      "File \u001B[1;32m~\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\anl2025tmp\\venv\\src\\negmas\\src\\negmas\\sao\\controllers.py:62\u001B[0m, in \u001B[0;36mSAOController.__init__\u001B[1;34m(self, default_negotiator_type, preferences, ufun, **kwargs)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ufun \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     61\u001B[0m     preferences \u001B[38;5;241m=\u001B[39m ufun\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_negotiator_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_negotiator_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[0;32m     64\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreferences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreferences\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m    \u001B[49m\u001B[43mufun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mufun\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\anl2025tmp\\venv\\src\\negmas\\src\\negmas\\negotiators\\controller.py:71\u001B[0m, in \u001B[0;36mController.__init__\u001B[1;34m(self, default_negotiator_type, default_negotiator_params, parent, auto_kill, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     65\u001B[0m     default_negotiator_type: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m TControlledNegotiator \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     70\u001B[0m ):\n\u001B[1;32m---> 71\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_negotiators: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, NegotiatorInfo] \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m default_negotiator_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mTypeError\u001B[0m: Rational.__init__() got an unexpected keyword argument 'private_info'"
     ]
    }
   ],
   "source": [
    "results = anl2024_tournament(\n",
    "    n_scenarios=1, n_repetitions=3, nologs=True, njobs=-1,\n",
    "    competitors=[MyRandom2025, Boulware]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f57349",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The score that is printed is the average advantage, which is the received utility minus the reservation value. We can immediately notice that `MyRandom2025` is getting a negative average advantage which means that it sometimes gets agreements that are worse than disagreement (i.e. with utility less than its reservation value). Can you guess why is this happening? How can we resolve that?\n",
    "\n",
    "You can easily check the final scores using the `final_scores` member of the returned [SimpleTournamentResults](https://negmas.readthedocs.io/en/latest/api/negmas.tournaments.SimpleTournamentResults.html) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-trading",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e132ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The returned results are all pandas dataframes. We can use standard pandas functions to get deeper understanding of the results. Here is how to plot a KDE figure (kind of histogram) comparing different strategies in this tournament. The higher the line, the more often this value of the advantage is observed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacae58-e02e-4981-bb12-890e6d55681a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "df = results.scores\n",
    "for label, data in df.groupby('strategy'):\n",
    "    data.advantage.plot(kind=\"kde\", ax=ax, label=label)\n",
    "plt.ylabel(\"advantage\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683a365-1f2e-4f1d-89c5-e169b00b5a68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(16,4))\n",
    "for i, col in enumerate([\"advantage\", \"welfare\", \"nash_optimality\"]):\n",
    "    results.scores.groupby(\"strategy\")[col].mean().sort_index().plot(kind=\"bar\", ax=axs[i])\n",
    "    axs[i].set_ylabel(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2507d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Available helpers\n",
    "\n",
    "Our negotiator was not so good but it exemplifies the simplest method for developing a negotiator in NegMAS. For more information refer to [NegMAS Documentation](https://negmas.readthedocs.io). You develop your agent, as explained above, by implementing the `__call__` method of your class.\n",
    "\n",
    "This method, receives an [SAOState](https://negmas.readthedocs.io/en/latest/api/negmas.sao.SAOState.html) which represents the current `state` of the negotiation. The most important members of this state object are `current_offer` which gives the current offer from the partner (or `None` if this is the beginning of the negotiation) and `relative_time` which gives the relative time of the negotiation ranging between `0` and `1`.\n",
    "\n",
    "It should return an [SAOResponse](https://negmas.readthedocs.io/en/latest/api/negmas.sao.SAOResponse.html) represeting the agent's `response` which consists of two parts:\n",
    "\n",
    "1. A [ResponseType](https://negmas.readthedocs.io/en/latest/api/negmas.gb.ResponseType.html) with the following allowed values:\n",
    "    - `ResponseType.ACCEPT_OFFER`, accepts the current offer (pass the current offer as the second member of the response).\n",
    "    - `ResponseType.REJECT_OFFER`, rejects the current offer (pass you counter-offer as the second member of the response).\n",
    "    - `ResponseType.END_NEGOTIATION`, ends the negotiation immediately (pass `None` as the second member of the response).\n",
    "2. A counter offer (in case of rejection), the received offer (in case of acceptance) or `None` if ending the negotiation.\n",
    "\n",
    "The negotiator can use the following objects to help it implement its strategy:\n",
    "\n",
    "- `self.nmi` A [SAONMI](https://negmas.readthedocs.io/en/latest/api/negmas.sao.SAONMI.html) that gives you access to all the settings of this negotiation and provide some simple helpers:\n",
    "    - `n_steps`, `time_limit` The number of rounds and seconds allowed for this negotiation (`None` means no limit).\n",
    "    - `random_outcomes(n)` Samples `n` random outcomes from this negotiation.\n",
    "    - `outcome_space` The [OutcomeSpace](https://negmas.readthedocs.io/en/latest/api/negmas.outcomes.OutcomeSpace.html) of the negotiation which represent all possible agreements. In ANL 2024, this will always be of type [DiscreteCartesianOutcomeSpace](https://negmas.readthedocs.io/en/latest/api/negmas.outcomes.DiscreteCartesianOutcomeSpace.html) with a single issue.\n",
    "    - `discrete_outcomes()` A generator of all outcomes in the outcome space.\n",
    "    - `log_info()` Logs structured information for this negotiator that can be checked in the logs later (Similarily there are `log_error`, `log_warning`, `log_debug`).\n",
    "- `self.ufun` A [LinearAdditiveUtilityFunction](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.LinearAdditiveUtilityFunction.html#negmas.preferences.LinearAdditiveUtilityFunction) representing the agent's own utility function. This object provides some helpful functionality including:\n",
    "   - `self.ufun.is_better(a, b)` Tests if outcome `a` is better than `b` (use `None` for disagreement). Similarily we have, `is_worse`, `is_not_worse` and `is_not_better`.\n",
    "   - `self.ufun.reserved_value` Your negotiator's reserved/reservation value (between 0 and 1). You can access this also as `self.ufun(None)`.\n",
    "   - `self.ufun(w)` Returns the utility value of the outcome `w`. It is recommended to cast this value to float (i.e. `float(self.ufun(w)`) to support probabilistic utility functions.\n",
    "   - `self.outcome_space` The [OutcomeSpace](https://negmas.readthedocs.io/en/latest/api/negmas.outcomes.OutcomeSpace.html) of the negotiation which represent all possible agreements. In ANL 2024, this will always be of type [DiscreteCartesianOutcomeSpace](https://negmas.readthedocs.io/en/latest/api/negmas.outcomes.DiscreteCartesianOutcomeSpace.html) with a single issue.\n",
    "   - `self.ufun.invert()` Returns and caches an [InverseUtilityFunction](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.InverseUFun.html#negmas.preferences.InverseUFun) object which can be used to find outcomes given their utilities. The most important services provided by the InverseUtilityFunction returned are:\n",
    "       - `minmax()` returns the minimum and maximum values of the ufun (will always be (0, 1) approximately in ANL 2024).\n",
    "       - `best()`, `worst()` returns the best (worst) outcomes.\n",
    "       - `one_in()`, `some_in()` returns one (or some) outcomes within the given range of utilities.\n",
    "       - `next_better()`, `next_worse()` returns the next outcome descendingly (ascendingly) in utility value.\n",
    "- `self.opponent_ufun` A [LinearAdditiveUtilityFunction](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.LinearAdditiveUtilityFunction.html#negmas.preferences.LinearAdditiveUtilityFunction) representing the **opponent's** utility function. You can access this also as `self.private_info[\"opponent_ufun\"]`. This utility function will have a zero reserved value independent of the opponent's true reserved value. You can actually set the reserved value on this object to your best estimate. All ufun funcationality is available in this object.\n",
    "\n",
    "\n",
    "Other than these objects, your negotiator can access any of the analytic facilities available in NegMAS. For example, you can calculate the [pareto_frontier](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.pareto_frontier.html), [Nash Bargaining Soluion](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.nash_points.html), [Kalai Bargaining Solution](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.kalai_points.html), [points with maximum wellfare](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.max_welfare_points.html), etc. You can check the implementation of the [NashSeeker](https://github.com/yasserfarouk/anl/blob/main/src/anl/anl2024/negotiators/builtins/nash_seeker.py) agent for examples of using these facilities.\n",
    "\n",
    "\n",
    "Other than implementing the `__call__`, method you can optionally implement one or more of the following callbacks to initialize your agent:\n",
    "\n",
    "- `on_negotiation_start(state: SAOState)` This [callback](https://negmas.readthedocs.io/en/latest/api/negmas.negotiators.EvaluatorNegotiator.html#negmas.negotiators.EvaluatorNegotiator.on_negotiation_start) is called once per negotiation after the ufuns are set but before any offers are exchanged.\n",
    "- `on_preferences_changed(changes)` This [callback](https://negmas.readthedocs.io/en/latest/api/negmas.negotiators.EvaluatorNegotiator.html#negmas.negotiators.EvaluatorNegotiator.on_preferences_changed) is called **whenever** your negotiator's ufun is changed. This will happen at the beginning of each negotiation but it can also happen again if the ufun is changed **while the negotiation is running**. In ANL 2024, ufuns never change during the negotiation so this callback is equivalent to `on_negotiation_start()` but for future proofness, you should use this callback for any initialization instead to guarantee that this initialization will be re-run in cases of changing utility function.\n",
    "\n",
    "## Understanding our negotiator\n",
    "\n",
    "Now we can analyze the simple random negotiator we developed earlier.\n",
    "\n",
    "- Firstly, we find the current offer that we need to respond to:\n",
    "  ```python\n",
    "  offer = state.current_offer\n",
    "  ```\n",
    "- **Acceptance Strategy** We then accept this offer if three conditions are satisfied:\n",
    "  - The offer is not `None` which means that we are not starting the negotiation just now:\n",
    "  - The offer is not worse than disagreement. This prevents us from accepting irrational outcomes.\n",
    "  - A random number we generated is less than 0.25. This means we accept rational offers with probability 25%.\n",
    "    ```python\n",
    "    if offer is not None and self.ufun.is_not_worse(offer, None) and random.random() < 0.25:\n",
    "        return SAOResponse(ResponseType.ACCEPT_OFFER, offer)\n",
    "    ```\n",
    "- **Offering Strategy** If we decided not to accept the offer, we simply generate a single random outcome and offer it:\n",
    "  ```python\n",
    "  return SAOResponse(ResponseType.REJECT_OFFER, self.nmi.random_outcomes(1)[0])\n",
    "  ```\n",
    "\n",
    "This negotiator did not use the fact that we know the opponent utility function up to reserved value. It did not even use the fact that we know our *own* utility function. As expected, it did not get a good score. Let's develop a simple yet more meaningful agent that uses both of these pieces of information.\n",
    "\n",
    "Can you now see why is this negotiator is getting negative advantages sometimes? We were careful in our acceptance strategy but not in our *offering strategy*. There is nothing in our code that prevents our negotiator from offering irrational outcomes (i.e. outcomes worse than disagreement for itself) and sometimes the opponent will just accept those. Can you fix this?\n",
    "\n",
    "## A more meaningful negotiator\n",
    "\n",
    "How can we use knowledge of our own and our opponent's utility functions (up to reserved value for them)? Here is one possibility:\n",
    "\n",
    "- **Acceptance Strategy** We accept offers that have a utility above some *aspiration* level. This aspiration level starts very high (1.0) and goes monotoncially down but never under the reserved value which is reached when the relative time is 1.0 (i.e. by the end of the negotiation). This is implemented in `is_acceptable()` below.\n",
    "- **Opponent Modeling** We estimate the opponent reserved value under the assumption that they are using a monotonically decreasing curve to select a utility value and offer an outcome around it. This is implemented in `update_reserved_value()` below.\n",
    "\n",
    "- **Bidding Strategy** Once we have an estimate of their reserved value, we can then find out all outcomes that are rational for both we and them. We can then check the relative time of the negotiation and offer outcomes by conceding over this list of rational outcomes. This is implemented in the `generate_offer()` method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b3007",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def aspiration_function(t, mx, rv, e):\n",
    "    \"\"\"A monotonically decreasing curve starting at mx (t=0) and ending at rv (t=1)\"\"\"\n",
    "    return (mx - rv) * (1.0 - np.power(t, e)) + rv\n",
    "\n",
    "\n",
    "class SimpleRVFitter(SAONegotiator):\n",
    "    \"\"\"A simple curve fitting modeling agent\"\"\"\n",
    "    def __init__(self, *args, e: float = 5.0, **kwargs):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.e = e\n",
    "        # keeps track of times at which the opponent offers\n",
    "        self.opponent_times: list[float] = []\n",
    "        # keeps track of opponent utilities of its offers\n",
    "        self.opponent_utilities: list[float] = []\n",
    "        # keeps track of our last estimate of the opponent reserved value\n",
    "        self._past_oppnent_rv = 0.0\n",
    "        # keeps track of the rational outcome set given our estimate of the\n",
    "        # opponent reserved value and our knowledge of ours\n",
    "        self._rational: list[tuple[float, float, Outcome]] = []\n",
    "\n",
    "    def __call__(self, state):\n",
    "        # update the opponent reserved value in self.opponent_ufun\n",
    "        self.update_reserved_value(state.current_offer, state.relative_time)\n",
    "        # run the acceptance strategy and if the offer received is acceptable, accept it\n",
    "        if self.is_acceptable(state.current_offer, state.relative_time):\n",
    "            return SAOResponse(ResponseType.ACCEPT_OFFER, state.current_offer)\n",
    "        # call the offering strategy\n",
    "        return SAOResponse(ResponseType.REJECT_OFFER, self.generate_offer(state.relative_time))\n",
    "\n",
    "    def generate_offer(self, relative_time) -> Outcome:\n",
    "        # The offering strategy\n",
    "        # We only update our estimate of the rational list of outcomes if it is not set or\n",
    "        # there is a change in estimated reserved value\n",
    "        if (\n",
    "            not self._rational\n",
    "            or abs(self.opponent_ufun.reserved_value - self._past_oppnent_rv) > 1e-3\n",
    "        ):\n",
    "            # The rational set of outcomes sorted dependingly according to our utility function\n",
    "            # and the opponent utility function (in that order).\n",
    "            self._rational = sorted(\n",
    "                [\n",
    "                    (my_util, opp_util, _)\n",
    "                    for _ in self.nmi.outcome_space.enumerate_or_sample(\n",
    "                        levels=10, max_cardinality=100_000\n",
    "                    )\n",
    "                    if (my_util := float(self.ufun(_))) > self.ufun.reserved_value\n",
    "                    and (opp_util := float(self.opponent_ufun(_)))\n",
    "                    > self.opponent_ufun.reserved_value\n",
    "                ],\n",
    "            )\n",
    "        # If there are no rational outcomes (e.g. our estimate of the opponent rv is very wrong),\n",
    "        # then just revert to offering our top offer\n",
    "        if not self._rational:\n",
    "            return self.ufun.best()\n",
    "        # find our aspiration level (value between 0 and 1) the higher the higher utility we require\n",
    "        asp = aspiration_function(relative_time, 1.0, 0.0, self.e)\n",
    "        # find the index of the rational outcome at the aspiration level (in the rational set of outcomes)\n",
    "        max_rational = len(self._rational) - 1\n",
    "        indx = max(0, min(max_rational, int(asp * max_rational)))\n",
    "        outcome = self._rational[indx][-1]\n",
    "        return outcome\n",
    "\n",
    "    def is_acceptable(self, offer, relative_time) -> bool:\n",
    "        \"\"\"The acceptance strategy\"\"\"\n",
    "        # If there is no offer, there is nothing to accept\n",
    "        if offer is None:\n",
    "            return False\n",
    "        # Find the current aspiration level\n",
    "        asp = aspiration_function(\n",
    "            relative_time, 1.0, self.ufun.reserved_value, self.e\n",
    "        )\n",
    "        # accept if the utility of the received offer is higher than\n",
    "        # the current aspiration\n",
    "        return float(self.ufun(offer)) >= asp\n",
    "\n",
    "    def update_reserved_value(self, offer, relative_time):\n",
    "        \"\"\"Learns the reserved value of the partner\"\"\"\n",
    "        if offer is None:\n",
    "            return\n",
    "        # save to the list of utilities received from the opponent and their times\n",
    "        self.opponent_utilities.append(float(self.opponent_ufun(offer)))\n",
    "        self.opponent_times.append(relative_time)\n",
    "        # Use curve fitting to estimate the opponent reserved value\n",
    "        # We assume the following:\n",
    "        # - The opponent is using a concession strategy with an exponent between 0.2, 5.0\n",
    "        # - The opponent never offers outcomes lower than their reserved value which means\n",
    "        #   that their rv must be no higher than the worst outcome they offered for themselves.\n",
    "        bounds = ((0.2, 0.0), (5.0, min(self.opponent_utilities)))\n",
    "        try:\n",
    "            optimal_vals, _ = curve_fit(\n",
    "                lambda x, e, rv: aspiration_function(\n",
    "                    x, self.opponent_utilities[0], rv, e\n",
    "                ),\n",
    "                self.opponent_times,\n",
    "                self.opponent_utilities,\n",
    "                bounds=bounds,\n",
    "            )\n",
    "            self._past_oppnent_rv = self.opponent_ufun.reserved_value\n",
    "            self.opponent_ufun.reserved_value = optimal_vals[1]\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c6506",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "anl2024_tournament(\n",
    "    n_scenarios=1, n_repetitions=3, nologs=True, njobs=-1,\n",
    "    competitors=[MyRandom2025, SimpleRVFitter, Boulware, Conceder]\n",
    ").final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8814f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Much better :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7704f09",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see how each part of this negotiator works and how they fit together.\n",
    "\n",
    "### Construction\n",
    "The first method of the negotiator to be called is the `__init__` method which is called when the negotiator is created **usually before the ufun is set**. You can use this method to construct the negotiator setting initial values for any variables you need to run your agent.\n",
    "\n",
    "An important thing to note here is that your negotiator **must** pass any parameters it does not use to its parent to make sure the object is constructed correctly. This is how we implement this in our `SimpleRVFitter`:\n",
    "\n",
    "```python\n",
    "def __init__(self, *args, e: float = 5.0, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "```\n",
    "\n",
    "We then set the variables we need for our negotiator:\n",
    "\n",
    "- `self.e` stores the exponent of the concession curve we will be use (more on that later).\n",
    "- `self.opponent_times`, `self.opponent_utilities` keep track of the times the opponent offers and its own utility of its offers. We will use that to estimate the opponent's reserved value using simple curve fitting in `update_reserved_values()`.\n",
    "- `self._past_oppnent_rv = 0.0` We start assuming that the opponent has zero reserved value. This is an optimistic assumption because it means that anything rational for us is rational for the opponent so we have more negotiation power.\n",
    "- `self._rational` This is where we will store the list of rational outcomes to concede over. For each outcome we will store our utility, opponent utility and the outcome itself (in that order).\n",
    "\n",
    "### Overall Algorithm\n",
    "\n",
    "The overall algorithm is implemented --- as usual --- in the `__call__()` method. This is the complete algorithm:\n",
    "\n",
    "```python\n",
    "def __call__(self, state):\n",
    "    self.update_reserved_value(state.current_offer, state.relative_time)\n",
    "    if self.is_acceptable(state.current_offer, state.relative_time):\n",
    "        return SAOResponse(ResponseType.ACCEPT_OFFER, state.current_offer)\n",
    "    return SAOResponse(ResponseType.REJECT_OFFER, self.generate_offer(state.relative_time))\n",
    "```\n",
    "\n",
    "We start by updating our estimate of the reserved value of the opponent using `update_reserved_value()`. We then call the acceptance strategy `is_acceptable()` to check whether the current offer should be accepted. If the current offer is not acceptable, we call the bidding strategy `generate_offer()` to generate a new offer which we return as our counter-offer. Simple!!\n",
    "\n",
    "### Opponent Modeling (Estimating Reserved Value)\n",
    "\n",
    "The first step is in our algorithm is to update our estimate of the opponent's reserved value. This is done in three simple steps:\n",
    "\n",
    "1. If we have not offer from the opponent, there is nothing to do. Just return:\n",
    "   ```python\n",
    "   if offer is None:\n",
    "        return\n",
    "   ```\n",
    "2. We append the time and opponent's utility to our running list of opponent offer utilities:\n",
    "   ```python\n",
    "   self.opponent_utilities.append(float(self.opponent_ufun(offer)))\n",
    "   self.opponent_times.append(relative_time)\n",
    "   ```\n",
    "3. We apply a simple [curve fitting](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) algorithm from [scipy](https://scipy.org) to estimate the opponent's reserved value (and its concession exponent but we are not going to use that):\n",
    "\n",
    "      - We set the bounds of the reserved value to be between zero (minimum possible value) and the minimum utility the opponent ever offered. This assumes that the opponent only offers rational outcomes for itself. The bounds for the concession curve are set to (0.2, 5.0) which is the usual range of exponents used by time-based strategies.\n",
    "      ```python\n",
    "      bounds = ((0.2, 0.0), (5.0, min(self.opponent_utilities)))\n",
    "      ```\n",
    "      - We then just apply curve fitting while keeping the old estimate. We keep the old estimate to check whether there is enough change to warrent reevaluation of the rational outcome sets in our offering strategy. We ignore any errors keeping the old estimate in that case.\n",
    "\n",
    "      ```python\n",
    "      optimal_vals, _ = curve_fit(\n",
    "          lambda x, e, rv: aspiration_function(x, self.opponent_utilities[0], rv, e),\n",
    "          self.opponent_times, self.opponent_utilities, bounds=bounds\n",
    "      )\n",
    "\n",
    "      ```\n",
    "      Note that we just pass `self.opponent_utilities[0]` as the maximum for the concession curve because we know that this is the utility of the first offer from the opponent.\n",
    "\n",
    "      - Finally, we update the opponent reserved value with our new estimate keeping the latest value for later:\n",
    "      ```python\n",
    "      self._past_oppnent_rv = self.opponent_ufun.reserved_value\n",
    "      self.opponent_ufun.reserved_value = optimal_vals[1]\n",
    "      ```\n",
    "\n",
    "### Acceptance Strategy\n",
    "\n",
    "Our acceptance strategy is implemented in `is_acceptable()` and consists of the following steps:\n",
    "\n",
    "1. Reject if no offer is found (i.e. we are starting the negotiation now):\n",
    "   ```python\n",
    "   if offer is None:\n",
    "       return False\n",
    "   ```\n",
    "2. Find our current aspiration level which starts at 1.0 (inidicating we will only accept our best offer in the first step) ending at our reserved value (indicating that we are willing to accept any rational outcome by the end of the negotiation). Use the exponent we stored during construction.\n",
    "   ```python\n",
    "   asp = aspiration_function(state.relative_time, 1.0, self.ufun.reserved_value, self.e)\n",
    "   ```\n",
    "3. Accept the offer iff its utility is higher than the aspiration level:\n",
    "    ```python\n",
    "    return float(self.ufun(offer)) >= asp\n",
    "    ```\n",
    "Note that this acceptance strategy does not use the estimated opponent reserved value (or the opponent's ufun) in any way.\n",
    "\n",
    "### Bidding Strategy\n",
    "\n",
    "Now that we have updated our estimate of the opponent reserved value and decided not to accept their offer, we have to generate our own offer which the job of the bidding strategy implementedin `generate_offer()`. This is done in three steps as well:\n",
    "\n",
    "1. If the difference between the current and last estimate of the opponent reserved value is large enough, we create the rational outcome list.\n",
    "    - This test is implemented by:\n",
    "    ```python\n",
    "    not self._rational or abs(self.opponent_ufun.reserved_value - self._past_oppnent_rv) > 1e-3\n",
    "    ```\n",
    "    - We then create of all outcomes prepending them with our and opponent's utility values:\n",
    "  ```python\n",
    "  [ (my_util, opp_util, _)\n",
    "    for _ in self.nmi.outcome_space.enumerate_or_sample(\n",
    "        levels=10, max_cardinality=100_000\n",
    "    )\n",
    "    if (\n",
    "        (my_util := float(self.ufun(_))) > self.ufun.reserved_value\n",
    "        and (opp_util := float(self.opponent_ufun(_))) > self.opponent_ufun.reserved_value\n",
    "  )]\n",
    "  ```\n",
    "    - Finally, we sort this list. Because each element is a tuple, the list will be sorted ascendingly by our utility with equal values sorted ascendingly by the opponent utility.\n",
    "  ```python\n",
    "  self._rational = sorted(...)\n",
    "  ```\n",
    "\n",
    "2. If there are no rational outcomes (e.g. our estimate of the opponent rv is very wrong), then just revert to offering our top offer\n",
    "   ```python\n",
    "   if not self._rational:\n",
    "        return self.ufun.best()\n",
    "   ```\n",
    "3. If we have a rational set, we calculate an aspiration level that starts at 1 and ends at 0 (note that we do not need to end at the reserved value because all outcomes in `self._rational` are already no worse than disagreement. We then calculate the outcome that is at the current aspiration level from the end of the rational outcome list and offer it:\n",
    "   ```python\n",
    "   asp = aspiration_function(relative_time, 1.0, 0.0, self.e)\n",
    "   max_rational = len(self._rational) - 1\n",
    "   indx = max(0, min(max_rational, int(asp * max_rational)))\n",
    "   outcome = self._rational[indx][-1]\n",
    "   return outcome\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9427f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Running a single negotiation\n",
    "\n",
    "What if we now want to see what happens in a single negotiation using our shiny new negotiator?\n",
    "We first need a scenario to define the outcome space and ufuns. We can then add negotiators to it and run it. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ba7a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from negmas.sao import SAOMechanism\n",
    "from anl.anl2024.runner import mixed_scenarios\n",
    "from anl.anl2024.negotiators.builtins import Linear\n",
    "\n",
    "# create a scenario\n",
    "s = mixed_scenarios(1)[0]\n",
    "# copy ufuns and set rv to 0 in the copies\n",
    "ufuns0 = [copy.deepcopy(u) for u in s.ufuns]\n",
    "for u in ufuns0:\n",
    "    u.reserved_value = 0.0\n",
    "# create the negotiation mechanism\n",
    "session = SAOMechanism(n_steps=1000, outcome_space=s.outcome_space)\n",
    "# add negotiators. Remember to pass the opponent_ufun in private_info\n",
    "session.add(\n",
    "    SimpleRVFitter(name=\"SimpleRVFitter\",\n",
    "                   private_info=dict(opponent_ufun=ufuns0[1]))\n",
    "    , ufun=s.ufuns[0]\n",
    ")\n",
    "session.add(Linear(name=\"Linear\"), ufun=s.ufuns[1])\n",
    "# run the negotiation and plot the results\n",
    "session.run()\n",
    "session.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0cab3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice how in the second half of the negotiation, the SimpleRVFitter is only offering outcomes that are rational for both negotiators (can you see that in the left-side plot? can you see it in the top right-side plot?). This means that the curve fitting approach is working OK here. The opponent is a time-based strategy in this case though.\n",
    "\n",
    "What happens if it was not? Let's try it against the builtin RVFitter for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d2fb1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from anl.anl2024.negotiators import RVFitter\n",
    "# create the negotiation mechanism\n",
    "session = SAOMechanism(n_steps=1000, outcome_space=s.outcome_space)\n",
    "# add negotiators. Remember to pass the opponent_ufun in private_info\n",
    "session.add(\n",
    "    SimpleRVFitter(name=\"SimpleRVFitter\",\n",
    "                   private_info=dict(opponent_ufun=ufuns0[1]))\n",
    "    , ufun=s.ufuns[0]\n",
    ")\n",
    "session.add(\n",
    "    RVFitter(name=\"RVFitter\",\n",
    "                   private_info=dict(opponent_ufun=ufuns0[0]))\n",
    "    , ufun=s.ufuns[1]\n",
    ")\n",
    "\n",
    "# run the negotiation and plot the results\n",
    "session.run()\n",
    "session.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29330184",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This time, our simple RV fitter could not really learn the opponent reserved value effectively. We can see that from the fact that it kept offering outcomes that are irrational for the opponent almost until the end of the negotiation.\n",
    "\n",
    "The builtin `RVFitter` seems better in this case. It took longer but it seems to only offer rational outcomes for its opponent (our SimpleRVFitter) after around 60% of the available negotiation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ed824",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Other Examples\n",
    "\n",
    "The ANL package comes with some example negotiators. These are not designed to be stong but to showcase how to use some of the features provided by the platform.\n",
    "\n",
    "- [MiCRO](https://github.com/yasserfarouk/anl/blob/main/src/anl/anl2024/negotiators/builtins/micro.py) A strong baseline behavioral negotiation strategy developed by de Jonge, Dave in \"An Analysis of the Linear Bilateral ANAC Domains Using the MiCRO Benchmark Strategy.\", ICJAI 2022. This strategy assumes no knowledge of the opponent utility function and is implemented from scratch to showcase the following:\n",
    "    - Using `on_preferences_changed` for initialization.\n",
    "    - Using [PresortingInverseUtilityFunction](https://negmas.readthedocs.io/en/latest/api/negmas.preferences.PresortingInverseUtilityFunction.html) for inverting a utility function.\n",
    "- [NashSeeker](https://github.com/yasserfarouk/anl/blob/main/src/anl/anl2024/negotiators/builtins/nash_seeker.py) A naive strategy that simply sets the opponent reserved value to a fixed value and then uses helpers from NegMAS to find the [Nash Bargaining Solution](https://en.wikipedia.org/wiki/Cooperative_bargaining) and use it for deciding what to offer. This showcases:\n",
    "    - Using NegMAS helpers to calculate the pareto-frontier and the Nash Bargaining Solution\n",
    "- [RVFitter](https://github.com/yasserfarouk/anl/blob/main/src/anl/anl2024/negotiators/builtins/rv_fitter.py) A strategy very similar to the one we implemented earlier as `SimpleRVFitter`. Instead of trying to estiamte the opponent reserved value from the first step, this strategy waits until it collects few offers before attempting the etimation. This showcases:\n",
    "    - Setting the opponent reserved value based on our best estimate.\n",
    "    - A simple way to use this estimate for our bidding strategy.\n",
    "    - Using **logging**. Logs can be saved using `self.nmi.log_info(dict(my_key=my_value))` and found under the logs folder.\n",
    "- [Boulware, Conceder, Linear](https://github.com/yasserfarouk/anl/blob/main/src/anl/anl2024/negotiators/builtins/wrappers.py) Time-based strategies that are implemented by just setting construction parameters of an existing NegMAS negotiator\n",
    "- [StochasticBoulware, StochasticConceder, StochasticLinear](https://github.com/yasserfarouk/anl/blob/main/src/anl/anl2024/negotiators/builtins/wrappers.py) Stochastic versions of the three time-based strategies above implemented by just setting construction parameters of an existing NegMAS negotiator\n",
    "- [NaiveTitForTat](https://github.com/yasserfarouk/anl/blob/main/src/anl/anl2024/negotiators/builtins/wrappers.py) A simple behavioral strategy implemented by just inheriting from an existing NegMAS negotiator.\n",
    "\n",
    "#### Note about running tournaments\n",
    "\n",
    "- When running a tournament using `anl2024_tournament` inside a Jupyter Notebook, you **must** pass `njobs=-1` to force serial execution of negotiations. This is required because the multiprocessing library used by NegMAS does not play nicely with Jupyter Notebooks. If you run the tournament using the same method from a `.py` python script file, you can omit this argument to run a tournament using all available cores.\n",
    "- When you pass `nologs=True`, no logs are stored for this tournament. If you omit this argument, a log will be created under `~/negmas/anl2024/tournaments` which can be visualized using the ANL visualizer by running:\n",
    "\n",
    "```bash\n",
    "anlv show\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.07502,
   "end_time": "2024-01-17T16:49:31.621882",
   "environment_variables": {},
   "exception": null,
   "input_path": "C:\\Users\\5856442\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\ANL\\notebooks\\tutorials\\tutorial.ipynb",
   "output_path": "C:\\Users\\5856442\\OneDrive - Universiteit Utrecht\\Documents\\GitHub\\ANL\\notebooks\\tutorials\\tutorial.ipynb",
   "parameters": {},
   "start_time": "2024-01-17T16:49:31.546862",
   "version": "2.3.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2cadc33b26404616ae0a695fd33d2ca8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4368ae6360eb453aaf61f264839b0ddb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "485a093637284ec28170f816ecd1fa92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "75d848742bcd4d8cb56a5457a57698c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83b5f1069c86434ba8abb01460027b86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2cadc33b26404616ae0a695fd33d2ca8",
       "placeholder": "​",
       "style": "IPY_MODEL_e9a077f7f68245d5b476e84fe61b2518",
       "value": ""
      }
     },
     "ad16d5ccfae94a6bab53b1e4f0d3b2fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae6ea78135ea49e79f65ded1eb5873f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d8c3b6c0996640e8aa5ff137cf69e906": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_83b5f1069c86434ba8abb01460027b86",
        "IPY_MODEL_f0bfa51dd65f45e89d271167128606e3",
        "IPY_MODEL_f3955f11b376489287a5e30e241fcee1"
       ],
       "layout": "IPY_MODEL_75d848742bcd4d8cb56a5457a57698c7"
      }
     },
     "e9a077f7f68245d5b476e84fe61b2518": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f0bfa51dd65f45e89d271167128606e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "info",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4368ae6360eb453aaf61f264839b0ddb",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_485a093637284ec28170f816ecd1fa92",
       "value": 0
      }
     },
     "f3955f11b376489287a5e30e241fcee1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad16d5ccfae94a6bab53b1e4f0d3b2fd",
       "placeholder": "​",
       "style": "IPY_MODEL_ae6ea78135ea49e79f65ded1eb5873f5",
       "value": " 0/? [00:00&lt;?, ?it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
